{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7b3d94-841b-4f3d-8255-bef740adcc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from uvicorn) (4.12.2)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Installing collected packages: uvicorn\n",
      "Successfully installed uvicorn-0.34.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe7afda-a5ba-4aff-96ab-a0f5c0317d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from fastapi) (4.12.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from starlette<0.46.0,>=0.40.0->fastapi) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, annotated-types, starlette, pydantic, fastapi\n",
      "Successfully installed annotated-types-0.7.0 fastapi-0.115.8 pydantic-2.10.6 pydantic-core-2.27.2 starlette-0.45.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4316496f-1c35-45c1-b234-a9a147f0f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: python-multipart\n",
      "Successfully installed python-multipart-0.0.20\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfc24cb-d5d3-470a-b01c-8c53a8bd3235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Prompt:\n",
      "\n",
      "New Design Description: A futuristic shoe design with aerodynamic curves and integrated sensor technology.\n",
      "Retrieved Similar Designs:\n",
      "- Case ID: design_6, Similarity Score: 0.75\n",
      "  Description: A futuristic design featuring sleek curves and integrated technology for enhanced performance.\n",
      "  Previous Feedback: The design aligns with emerging trends and appears manufacturable with current technologies.\n",
      "- Case ID: design_2, Similarity Score: 0.75\n",
      "  Description: An athletic shoe featuring enhanced grip and robust material choices.\n",
      "  Previous Feedback: The design is functional but appears bulky for high-speed movement.\n",
      "- Case ID: design_1, Similarity Score: 0.75\n",
      "  Description: A modern sneaker with minimalist design and ergonomic features.\n",
      "  Previous Feedback: The design is sleek but may require improvements in the sole design.\n",
      "\n",
      "Provide detailed feedback on manufacturability, suggestions for improvement, and reference similar cases.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Simulated o1 API Response:\n",
      "\n",
      "{'feasibility_score': 80, 'feedback': 'The design is innovative but might face challenges in material integration. Consider revising the curvature for improved manufacturability and testing alternative sensor placements.', 'suggestions': ['Refine the curve of the sole to reduce production complexity.', 'Experiment with alternate materials that better integrate with embedded sensors.'], 'retrieval_details': [{'case_id': 'design_6', 'similarity_score': 0.9, 'relevant_point': 'Similar futuristic design approach.'}, {'case_id': 'design_2', 'similarity_score': 0.85, 'relevant_point': 'Comparable emphasis on innovative features.'}]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration & Global Settings\n",
    "# -------------------------------\n",
    "EMBEDDING_DIM = 512  # Example embedding dimension\n",
    "\n",
    "# -------------------------------\n",
    "# Embedding Generation Module\n",
    "# -------------------------------\n",
    "def generate_text_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Dummy text embedding generation.\n",
    "    For reproducibility, seed NumPy's random generator with a hash of the text.\n",
    "    \"\"\"\n",
    "    np.random.seed(abs(hash(text)) % (2**32))\n",
    "    return np.random.rand(EMBEDDING_DIM)\n",
    "\n",
    "# -------------------------------\n",
    "# Similarity Search Module\n",
    "# -------------------------------\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "def similarity_search(query_embedding: np.ndarray, database: list, k: int = 3):\n",
    "    \"\"\"\n",
    "    Perform a similarity search over the synthetic database by computing cosine similarity.\n",
    "    Returns the top-k similar designs with their metadata and similarity scores.\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for entry in database:\n",
    "        emb = generate_text_embedding(entry[\"description\"])\n",
    "        sim = cosine_similarity(query_embedding, emb)\n",
    "        similarities.append((sim, entry))\n",
    "    # Sort in descending order of similarity.\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# -------------------------------\n",
    "# Prompt Construction & o1 API Simulation\n",
    "# -------------------------------\n",
    "def construct_prompt(new_design_text: str, retrieved_entries: list) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt that includes the new design description and retrieved similar cases.\n",
    "    \"\"\"\n",
    "    prompt = f\"New Design Description: {new_design_text}\\n\"\n",
    "    prompt += \"Retrieved Similar Designs:\\n\"\n",
    "    for sim, entry in retrieved_entries:\n",
    "        prompt += (\n",
    "            f\"- Case ID: {entry['id']}, Similarity Score: {sim:.2f}\\n\"\n",
    "            f\"  Description: {entry['description']}\\n\"\n",
    "            f\"  Previous Feedback: {entry['feedback']}\\n\"\n",
    "        )\n",
    "    prompt += \"\\nProvide detailed feedback on manufacturability, suggestions for improvement, and reference similar cases.\"\n",
    "    return prompt\n",
    "\n",
    "def call_o1_api(prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    Dummy function to simulate a call to the o1 API for generative feedback.\n",
    "    In a real-world scenario, this would involve making an HTTP request to an external API.\n",
    "    \"\"\"\n",
    "    simulated_response = {\n",
    "        \"feasibility_score\": 80,\n",
    "        \"feedback\": (\n",
    "            \"The design is innovative but might face challenges in material integration. \"\n",
    "            \"Consider revising the curvature for improved manufacturability and testing alternative sensor placements.\"\n",
    "        ),\n",
    "        \"suggestions\": [\n",
    "            \"Refine the curve of the sole to reduce production complexity.\",\n",
    "            \"Experiment with alternate materials that better integrate with embedded sensors.\"\n",
    "        ],\n",
    "        \"retrieval_details\": [\n",
    "            {\"case_id\": \"design_6\", \"similarity_score\": 0.90, \"relevant_point\": \"Similar futuristic design approach.\"},\n",
    "            {\"case_id\": \"design_2\", \"similarity_score\": 0.85, \"relevant_point\": \"Comparable emphasis on innovative features.\"}\n",
    "        ]\n",
    "    }\n",
    "    return simulated_response\n",
    "\n",
    "# -------------------------------\n",
    "# Synthetic Data & Execution\n",
    "# -------------------------------\n",
    "\n",
    "# Synthetic new design text (only text description)\n",
    "new_design_text = \"A futuristic shoe design with aerodynamic curves and integrated sensor technology.\"\n",
    "\n",
    "# Synthetic database (only text descriptions)\n",
    "synthetic_database = [\n",
    "    {\n",
    "        \"id\": \"design_1\",\n",
    "        \"description\": \"A modern sneaker with minimalist design and ergonomic features.\",\n",
    "        \"feedback\": \"The design is sleek but may require improvements in the sole design.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_2\",\n",
    "        \"description\": \"An athletic shoe featuring enhanced grip and robust material choices.\",\n",
    "        \"feedback\": \"The design is functional but appears bulky for high-speed movement.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_3\",\n",
    "        \"description\": \"A retro-style running shoe with classic aesthetics and modern comfort.\",\n",
    "        \"feedback\": \"Appealing design but may present challenges in mass production.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_4\",\n",
    "        \"description\": \"A lightweight training shoe with breathable fabric and flexible design.\",\n",
    "        \"feedback\": \"Manufacturing is straightforward, though material costs are a concern.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_5\",\n",
    "        \"description\": \"A high-performance shoe with advanced cushioning and innovative support.\",\n",
    "        \"feedback\": \"The cushioning technology is untested, requiring further prototyping.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_6\",\n",
    "        \"description\": \"A futuristic design featuring sleek curves and integrated technology for enhanced performance.\",\n",
    "        \"feedback\": \"The design aligns with emerging trends and appears manufacturable with current technologies.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Generate the query embedding for the new design text.\n",
    "query_embedding = generate_text_embedding(new_design_text)\n",
    "\n",
    "# Perform a similarity search over the synthetic database.\n",
    "retrieved_entries = similarity_search(query_embedding, synthetic_database, k=3)\n",
    "\n",
    "# Construct the prompt that includes the new design and similar designs from the database.\n",
    "prompt = construct_prompt(new_design_text, retrieved_entries)\n",
    "\n",
    "# Print the constructed prompt.\n",
    "print(\"Constructed Prompt:\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Simulate a call to the o1 API to get feedback.\n",
    "response = call_o1_api(prompt)\n",
    "\n",
    "# Print the simulated API response.\n",
    "print(\"Simulated o1 API Response:\\n\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49ca14-1901-4126-85a7-59731c009d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sentence-transformers) (2.4.0a0+gitb4b81bd)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sentence-transformers) (0.27.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages/fsspec-2024.10.0-py3.10.egg (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy<=1.12.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from sympy<=1.12.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m169.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers, sentence-transformers\n",
      "Successfully installed sentence-transformers-3.4.1 tokenizers-0.21.0 transformers-4.48.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4ca153-06e1-425c-a677-e361aa5bdd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "Using the `SDPA` attention implementation on multi-gpu setup with ROCM may lead to performance issues due to the FA backend. Disabling it to use alternative backends.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Prompt:\n",
      "\n",
      "New Design Description: A futuristic shoe design with aerodynamic curves, integrated sensor technology, and modular components.\n",
      "New Design Image URL: https://i.pinimg.com/736x/99/1c/3c/991c3cb2973e5ad58aa54c8a1512aa7f.jpg\n",
      "Retrieved Similar Designs:\n",
      "- Case ID: design_5, Similarity Score: 0.69\n",
      "  Description: A high-performance shoe featuring advanced cushioning and innovative support systems.\n",
      "  Previous Feedback: Innovative concept, but prototyping is needed for the support mechanisms.\n",
      "- Case ID: design_3, Similarity Score: 0.65\n",
      "  Description: A retro running shoe that combines classic aesthetics with modern cushioning.\n",
      "  Previous Feedback: Charming design but may require adjustments in production technique.\n",
      "- Case ID: design_2, Similarity Score: 0.64\n",
      "  Description: An athletic shoe with enhanced grip and robust materials for outdoor use.\n",
      "  Previous Feedback: Solid design, though the upper construction may be complex.\n",
      "\n",
      "Based on the above information, provide detailed feedback on the manufacturability of the new design. Include suggestions for improvements and specify the detailed areas of focus in the attached design image where improvements are needed (e.g., curvature adjustments, sensor integration areas, etc.).\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Simulated o1 API Response:\n",
      "\n",
      "{'feasibility_score': 82, 'feedback': 'The design demonstrates innovative features; however, certain areas in the design image require closer attention. In particular, the curvature near the heel and the sensor integration on the upper part need refinement to ensure manufacturability.', 'suggestions': ['Refine the curvature of the heel to improve stability during production.', 'Reassess sensor placement on the upper section for better integration and durability.'], 'detailed_image_focus': {'heel_area': 'The aggressive curvature may lead to manufacturing issues; consider smoothing this area.', 'upper_sensor_area': 'Sensor placement appears misaligned with optimal production guidelines; reposition as needed.'}, 'retrieval_details': [{'case_id': 'design_6', 'similarity_score': 0.9, 'relevant_point': 'Demonstrates a similar futuristic design approach.'}, {'case_id': 'design_2', 'similarity_score': 0.85, 'relevant_point': 'Emphasizes innovative features that align with the new design.'}]}\n"
     ]
    }
   ],
   "source": [
    "# Uncomment these lines if running in a new Colab environment:\n",
    "# !pip install sentence-transformers transformers\n",
    "# !pip install pillow\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------\n",
    "# Load Models for Embedding Generation\n",
    "# -------------------------------\n",
    "# Load SentenceTransformer for text embeddings.\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load CLIP model and processor for image embeddings.\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# -------------------------------\n",
    "# Embedding Generation Module\n",
    "# -------------------------------\n",
    "def generate_text_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a text embedding using SentenceTransformer.\n",
    "    \"\"\"\n",
    "    return text_model.encode(text)\n",
    "\n",
    "def generate_image_embedding(image_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate an image embedding using the CLIP model.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = clip_model.get_image_features(**inputs)\n",
    "    embedding = outputs.detach().numpy().flatten()\n",
    "    return embedding\n",
    "\n",
    "# -------------------------------\n",
    "# Similarity Search Module (Text Only)\n",
    "# -------------------------------\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "def similarity_search(query_embedding: np.ndarray, database: list, k: int = 3):\n",
    "    \"\"\"\n",
    "    Perform similarity search on the synthetic text database.\n",
    "    For each database entry, generate its text embedding and compute cosine similarity.\n",
    "    Returns the top-k similar entries along with their similarity scores.\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for entry in database:\n",
    "        emb = generate_text_embedding(entry[\"description\"])\n",
    "        sim = cosine_similarity(query_embedding, emb)\n",
    "        similarities.append((sim, entry))\n",
    "    # Sort the entries by similarity (highest first)\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# -------------------------------\n",
    "# Prompt Construction & o1 API Simulation\n",
    "# -------------------------------\n",
    "def construct_prompt(new_design_text: str, new_design_image_url: str, retrieved_entries: list) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt that includes:\n",
    "      - The new design text.\n",
    "      - The new design image URL.\n",
    "      - A list of retrieved similar designs from the synthetic database.\n",
    "    The prompt instructs the API to return manufacturability feedback,\n",
    "    suggestions for improvements, and detailed areas of focus in the design image.\n",
    "    \"\"\"\n",
    "    prompt = f\"New Design Description: {new_design_text}\\n\"\n",
    "    prompt += f\"New Design Image URL: {new_design_image_url}\\n\"\n",
    "    prompt += \"Retrieved Similar Designs:\\n\"\n",
    "    for sim, entry in retrieved_entries:\n",
    "        prompt += (\n",
    "            f\"- Case ID: {entry['id']}, Similarity Score: {sim:.2f}\\n\"\n",
    "            f\"  Description: {entry['description']}\\n\"\n",
    "            f\"  Previous Feedback: {entry['feedback']}\\n\"\n",
    "        )\n",
    "    prompt += (\n",
    "        \"\\nBased on the above information, provide detailed feedback on the manufacturability \"\n",
    "        \"of the new design. Include suggestions for improvements and specify the detailed areas \"\n",
    "        \"of focus in the attached design image where improvements are needed (e.g., curvature adjustments, sensor integration areas, etc.).\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def call_o1_api(prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    Dummy function to simulate a call to the o1 API.\n",
    "    In production, this would be an HTTP call to the external API.\n",
    "    \"\"\"\n",
    "    simulated_response = {\n",
    "        \"feasibility_score\": 82,\n",
    "        \"feedback\": (\n",
    "            \"The design demonstrates innovative features; however, certain areas in the design image \"\n",
    "            \"require closer attention. In particular, the curvature near the heel and the sensor integration \"\n",
    "            \"on the upper part need refinement to ensure manufacturability.\"\n",
    "        ),\n",
    "        \"suggestions\": [\n",
    "            \"Refine the curvature of the heel to improve stability during production.\",\n",
    "            \"Reassess sensor placement on the upper section for better integration and durability.\"\n",
    "        ],\n",
    "        \"detailed_image_focus\": {\n",
    "            \"heel_area\": \"The aggressive curvature may lead to manufacturing issues; consider smoothing this area.\",\n",
    "            \"upper_sensor_area\": \"Sensor placement appears misaligned with optimal production guidelines; reposition as needed.\"\n",
    "        },\n",
    "        \"retrieval_details\": [\n",
    "            {\"case_id\": \"design_6\", \"similarity_score\": 0.90, \"relevant_point\": \"Demonstrates a similar futuristic design approach.\"},\n",
    "            {\"case_id\": \"design_2\", \"similarity_score\": 0.85, \"relevant_point\": \"Emphasizes innovative features that align with the new design.\"}\n",
    "        ]\n",
    "    }\n",
    "    return simulated_response\n",
    "\n",
    "# -------------------------------\n",
    "# Synthetic Data & Execution\n",
    "# -------------------------------\n",
    "\n",
    "# Synthetic new design text.\n",
    "new_design_text = \"A futuristic shoe design with aerodynamic curves, integrated sensor technology, and modular components.\"\n",
    "\n",
    "# For demonstration, assume the new design image is available locally at \"./design.jpg\"\n",
    "# and its URL (after being hosted) is as follows:\n",
    "new_design_image_url = \"https://i.pinimg.com/736x/99/1c/3c/991c3cb2973e5ad58aa54c8a1512aa7f.jpg\"\n",
    "\n",
    "# Optionally, generate the image embedding (not used in similarity search here)\n",
    "# image_embedding = generate_image_embedding(\"./design.jpg\")\n",
    "\n",
    "# Synthetic database (text descriptions only).\n",
    "synthetic_database = [\n",
    "    {\n",
    "        \"id\": \"design_1\",\n",
    "        \"description\": \"A modern sneaker with minimalist design and ergonomic features.\",\n",
    "        \"feedback\": \"Sleek design but potential issues with sole durability.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_2\",\n",
    "        \"description\": \"An athletic shoe with enhanced grip and robust materials for outdoor use.\",\n",
    "        \"feedback\": \"Solid design, though the upper construction may be complex.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_3\",\n",
    "        \"description\": \"A retro running shoe that combines classic aesthetics with modern cushioning.\",\n",
    "        \"feedback\": \"Charming design but may require adjustments in production technique.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_4\",\n",
    "        \"description\": \"A lightweight training shoe emphasizing breathability and flexibility.\",\n",
    "        \"feedback\": \"Efficient design, yet the material composition could be improved.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_5\",\n",
    "        \"description\": \"A high-performance shoe featuring advanced cushioning and innovative support systems.\",\n",
    "        \"feedback\": \"Innovative concept, but prototyping is needed for the support mechanisms.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"design_6\",\n",
    "        \"description\": \"A futuristic design with sleek curves and integrated technology for enhanced performance.\",\n",
    "        \"feedback\": \"Aligns with modern trends and appears manufacturable with current technologies.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Generate query embedding for the new design text.\n",
    "query_embedding = generate_text_embedding(new_design_text)\n",
    "\n",
    "# Perform similarity search over the synthetic database.\n",
    "retrieved_entries = similarity_search(query_embedding, synthetic_database, k=3)\n",
    "\n",
    "# Construct the prompt including the new design text, image URL, and similar designs.\n",
    "prompt = construct_prompt(new_design_text, new_design_image_url, retrieved_entries)\n",
    "\n",
    "# Print the constructed prompt.\n",
    "print(\"Constructed Prompt:\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Simulate a call to the o1 API to get feedback.\n",
    "response = call_o1_api(prompt)\n",
    "\n",
    "# Print the simulated API response.\n",
    "print(\"Simulated o1 API Response:\\n\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5111a-f86e-4d37-b51a-0d8d4331381d",
   "metadata": {},
   "source": [
    "# pdf reader API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9ec00e-9d54-408b-90b9-81398f09deff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b960b243-c634-4ffd-9509-98c883152550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.61.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Downloading openai-1.61.0-py3-none-any.whl (460 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 openai-1.61.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aadd4ea5-7ad3-4d61-830e-2e42adab56a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b1ea1e-543b-4a41-8a8f-ddb7dd0ffe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Calling OpenAI API for feedback...\n",
      "\n",
      "----- OpenAI API Feedback -----\n",
      "\n",
      "**Evaluation of the New Futuristic Shoe Design**\n",
      "\n",
      "**1. Manufacturability:**\n",
      "- **Material Integration:** The design integrates modular components and sensors, which suggests the use of advanced materials such as flexible PCBs (Printed Circuit Boards) and adaptive polymers. The primary concern here is the seamless integration of these materials into the manufacturable scheme. Ensuring compatibility and resilience in the bonding methods, such as using ultrasonic welding or laser welding for sensor integration, is crucial. Past cases like design_2, which highlighted complexity in upper construction, suggest a meticulous approach to integrating such multifaceted elements without compromising structural integrity.\n",
      "- **Curvature Optimization:** The design displays aerodynamic curves which add aesthetic value and could potentially enhance performance. However, the manufacturability of these curves, particularly in areas like the sole and heel, require attention. From the feedback in design_5 and leveraging the aerodynamic aspect, it could be beneficial to utilize 3D printing techniques initially to prototype these curvatures accurately, ensuring they can be mass-produced using conventional molding methods without losing their functional benefits.\n",
      "- **Sensor Placement:** Placement strategies for integrated sensors must ensure their functionality and minimal interference with user comfort. Sensors likely include pressure, temperature, and motion units. Key zones for placement are under the heel, the arch, and near the toe box to capture comprehensive data on user movement and impact zones. Translating design_3’s suggestions, positioning sensors where they can be most protected by the shoe materials, yet still effectively gather data, will be critical. Additionally, user access for maintenance or replacement as part of the modular component design should be considered.\n",
      "\n",
      "**2. Practical Manufacturability:**\n",
      "- **Production Techniques:** The integration of modern and possibly custom cushioning materials, as touched upon in design_3, could require updated production techniques. Hybrid techniques combining both traditional shoe making and modern fabrication such as injection molding for the modularity components may be necessary. Guidelines suggest flexibility in design representation which should extend to production - adopting adaptable techniques that can handle material diversity and complexity in shoe architecture.\n",
      "- **Tooling and Molds:** Considering the PDF guideline querying existing outsole molds, it's cost-effective and practical to adapt current molds wherever possible. For entirely new elements or highly customized curves and designs, creating new molds must be justified by either significantly enhanced functionality or market demand to absorb the upfront investment.\n",
      "\n",
      "**3. Recommendations:**\n",
      "- **Prototyping:** Early and iterative prototyping is recommended, especially focusing on the integration of sensors and the feasibility of the modular components. Using design verification simulations and initial user testing rounds can help refine these aspects before full-scale production.\n",
      "- **Cost Analysis:** A thorough cost analysis for new materials, production methods, and potential need for new tooling should be conducted. Cost impacts should be balanced against expected market price points and consumer willingness to pay for advanced shoe technology.\n",
      "- **Feedback Cycles:** Engage in consumer feedback early in the process. Given the innovative nature of the shoe, understanding market needs and potential usability issues can drive design adjustments that enhance manufacturability and market success.\n",
      "\n",
      "**Feasibility Score: 75/100**\n",
      "The design is ambitious and holds market potential; however, the complexity of material integration, sensor embedding, and new production techniques present challenges that need to be addressed through rigorous testing and iteration.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pdfplumber\n",
    "import base64\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# ================================\n",
    "# Initialize Models for Embeddings\n",
    "# ================================\n",
    "# Text embedding model (for design descriptions and PDF text)\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# CLIP model and processor (for image embeddings)\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# ================================\n",
    "# PDF Extraction Functions\n",
    "# ================================\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    return text\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_folder=\"extracted_images\"):\n",
    "    \"\"\"Extract images from a PDF and save them as files.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    image_paths = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            for j, img in enumerate(page.images):\n",
    "                # This assumes the image stream is available as `img[\"stream\"]`\n",
    "                img_path = os.path.join(output_folder, f\"image_{i}_{j}.jpg\")\n",
    "                with open(img_path, \"wb\") as img_file:\n",
    "                    img_file.write(img[\"stream\"].get_data())\n",
    "                image_paths.append(img_path)\n",
    "    return image_paths\n",
    "\n",
    "# ================================\n",
    "# Embedding Generation Functions\n",
    "# ================================\n",
    "def generate_text_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"Generate a text embedding using SentenceTransformer.\"\"\"\n",
    "    return text_model.encode(text)\n",
    "\n",
    "def generate_image_embedding_from_url(image_url: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Download an image from a URL and generate an embedding using CLIP.\n",
    "    \"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = clip_model.get_image_features(**inputs)\n",
    "    return outputs.detach().numpy().flatten()\n",
    "\n",
    "def generate_image_embedding(image_path: str) -> np.ndarray:\n",
    "    \"\"\"Generate an image embedding using CLIP from a local image file.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = clip_model.get_image_features(**inputs)\n",
    "    return outputs.detach().numpy().flatten()\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "# ================================\n",
    "# Similarity Search over Synthetic Database\n",
    "# ================================\n",
    "def similarity_search(query_embedding: np.ndarray, database: list, k: int = 3):\n",
    "    \"\"\"\n",
    "    For each entry in the synthetic database (which has a 'description' field),\n",
    "    generate an embedding and compute cosine similarity with the query.\n",
    "    Return the top k entries (as tuples: (similarity, entry)).\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for entry in database:\n",
    "        entry_embedding = generate_text_embedding(entry[\"description\"])\n",
    "        sim = cosine_similarity(query_embedding, entry_embedding)\n",
    "        similarities.append((sim, entry))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# ================================\n",
    "# Similarity Search over PDF Text\n",
    "# ================================\n",
    "def split_text_into_chunks(text: str, chunk_size: int = 500):\n",
    "    \"\"\"Split text into chunks roughly of size 'chunk_size'. Splits on double-newlines if possible.\"\"\"\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    chunks = []\n",
    "    for p in paragraphs:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        if len(p) > chunk_size:\n",
    "            for i in range(0, len(p), chunk_size):\n",
    "                chunk = p[i:i+chunk_size]\n",
    "                chunks.append(chunk)\n",
    "        else:\n",
    "            chunks.append(p)\n",
    "    return chunks\n",
    "\n",
    "def similarity_search_pdf_text(query_embedding: np.ndarray, pdf_text: str, k: int = 2):\n",
    "    \"\"\"\n",
    "    Split the PDF text into chunks and compute similarity with the query embedding.\n",
    "    Returns the top k text chunks (as tuples: (similarity, chunk)).\n",
    "    \"\"\"\n",
    "    chunks = split_text_into_chunks(pdf_text)\n",
    "    similarities = []\n",
    "    for chunk in chunks:\n",
    "        emb = generate_text_embedding(chunk)\n",
    "        sim = cosine_similarity(query_embedding, emb)\n",
    "        similarities.append((sim, chunk))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# ================================\n",
    "# Similarity Search over PDF Images\n",
    "# ================================\n",
    "def similarity_search_pdf_images(new_design_image_url: str, pdf_image_paths: list, k: int = 1):\n",
    "    \"\"\"\n",
    "    Compare the new design image (downloaded from its URL) to each PDF image using CLIP embeddings.\n",
    "    Return the top k PDF images (as tuples: (similarity, image_path)).\n",
    "    \"\"\"\n",
    "    new_design_embedding = generate_image_embedding_from_url(new_design_image_url)\n",
    "    similarities = []\n",
    "    for image_path in pdf_image_paths:\n",
    "        pdf_image_embedding = generate_image_embedding(image_path)\n",
    "        sim = cosine_similarity(new_design_embedding, pdf_image_embedding)\n",
    "        similarities.append((sim, image_path))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# ================================\n",
    "# Construct Final Prompt Function\n",
    "# ================================\n",
    "def construct_prompt(new_design_text: str,\n",
    "                     new_design_image_url: str,\n",
    "                     retrieved_entries: list,\n",
    "                     pdf_relevant_texts: list) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt that includes:\n",
    "      - New design description and image URL.\n",
    "      - Retrieved similar cases from the synthetic database.\n",
    "      - Top similar text chunks from the PDF.\n",
    "    The prompt instructs the model to output a feasibility_score (0-100) along with very specific feedback.\n",
    "    \"\"\"\n",
    "    prompt = f\"New Design Description:\\n{new_design_text}\\n\\n\"\n",
    "    prompt += f\"New Design Image URL:\\n{new_design_image_url}\\n\\n\"\n",
    "    \n",
    "    prompt += \"Retrieved Similar Designs from Synthetic Database:\\n\"\n",
    "    for sim, entry in retrieved_entries:\n",
    "        prompt += f\"- Case ID: {entry['id']}, Similarity Score: {sim:.2f}\\n\"\n",
    "        prompt += f\"  Description: {entry['description']}\\n\"\n",
    "        prompt += f\"  Previous Feedback: {entry['feedback']}\\n\\n\"\n",
    "    \n",
    "    prompt += \"Relevant Domain Guidelines from PDF (Text):\\n\"\n",
    "    for sim, text_chunk in pdf_relevant_texts:\n",
    "        prompt += f\"- Similarity Score: {sim:.2f}\\n{text_chunk}\\n\\n\"\n",
    "    \n",
    "    # prompt += \"Relevant Domain Guideline Images from PDF (Base64 Encoded):\\n\"\n",
    "    # for sim, image_path in pdf_relevant_images:\n",
    "    #     with open(image_path, \"rb\") as img_file:\n",
    "    #         base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "    #         encoded_str = f\"data:image/jpeg;base64,{base64_image}\"\n",
    "    #     prompt += f\"- Similarity Score: {sim:.2f}\\n{encoded_str}\\n\\n\"\n",
    "    \n",
    "    prompt += (\n",
    "        \"Based on the above information, please provide a detailed evaluation including a feasibility_score (0-100) \"\n",
    "        \"and very specific, applicable feedback and suggestions for improving the manufacturability of the new design. \"\n",
    "        \"Reference specific aspects of the new design image (e.g., heel curvature, sensor integration zones) as well as \"\n",
    "        \"the retrieved similar cases and the domain guidelines extracted from the PDF.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# ================================\n",
    "# OpenAI Chat API Call Function (Updated)\n",
    "# ================================\n",
    "def chat_with_openai(conversation_history, api_key):\n",
    "    \"\"\"Interact with OpenAI API using the latest interface.\"\"\"\n",
    "    client = openai.OpenAI(api_key=api_key)  # Create an OpenAI client\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=conversation_history\n",
    "    )\n",
    "    return response.choices[0].message.content  # Access response correctly\n",
    "\n",
    "# ================================\n",
    "# Main Function\n",
    "# ================================\n",
    "def main():\n",
    "    # File paths and API key\n",
    "    pdf_path = \"./data/pdf/How_Shoes_Are_Made_Download_Edtion3.pdf\"    # PDF with domain guidelines\n",
    "    new_design_image_url = \"https://media.licdn.com/dms/image/v2/D4D34AQEoKT5kznwQNg/ugc-proxy-shrink_1280_800/ugc-proxy-shrink_1280_800/0/1719425797541?e=2147483647&v=beta&t=1izdwX_mPz9EjI5QYzaUfw7eHikndwlAoILkx-BT8TI\"  # Hosted URL for the new design image\n",
    "    api_key = \"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\"\n",
    "    \n",
    "    # New design description text.\n",
    "    new_design_text = (\n",
    "        \"A futuristic shoe design with aerodynamic curves, integrated sensor technology, and modular components. \"\n",
    "        \"The design aims to merge cutting-edge aesthetics with practical manufacturability.\"\n",
    "    )\n",
    "    \n",
    "    # --- RAG on Synthetic Database ---\n",
    "    synthetic_database = [\n",
    "        {\n",
    "            \"id\": \"design_1\",\n",
    "            \"description\": \"A modern sneaker with minimalist design and ergonomic features.\",\n",
    "            \"feedback\": \"Sleek design but potential issues with sole durability.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"design_2\",\n",
    "            \"description\": \"An athletic shoe with enhanced grip and robust materials for outdoor use.\",\n",
    "            \"feedback\": \"Solid design, though the upper construction may be complex.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"design_3\",\n",
    "            \"description\": \"A retro running shoe that combines classic aesthetics with modern cushioning.\",\n",
    "            \"feedback\": \"Charming design but may require adjustments in production technique.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"design_4\",\n",
    "            \"description\": \"A lightweight training shoe emphasizing breathability and flexibility.\",\n",
    "            \"feedback\": \"Efficient design, yet the material composition could be improved.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"design_5\",\n",
    "            \"description\": \"A high-performance shoe featuring advanced cushioning and innovative support systems.\",\n",
    "            \"feedback\": \"Innovative concept, but prototyping is needed for the support mechanisms.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"design_6\",\n",
    "            \"description\": \"A futuristic design with sleek curves and integrated technology for enhanced performance.\",\n",
    "            \"feedback\": \"Aligns with modern trends and appears manufacturable with current technologies.\"\n",
    "        },\n",
    "\n",
    "    ]\n",
    "    \n",
    "    # Generate an embedding for the new design text.\n",
    "    query_embedding = generate_text_embedding(new_design_text)\n",
    "    # Retrieve top similar cases from the synthetic database.\n",
    "    retrieved_entries = similarity_search(query_embedding, synthetic_database, k=3)\n",
    "    \n",
    "    # --- RAG on PDF Text ---\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    pdf_relevant_texts = similarity_search_pdf_text(query_embedding, pdf_text, k=2)\n",
    "    \n",
    "    # --- RAG on PDF Images ---\n",
    "    # print(\"Extracting images from PDF...\")\n",
    "    # pdf_image_paths = extract_images_from_pdf(pdf_path)\n",
    "    # pdf_relevant_images = similarity_search_pdf_images(new_design_image_url, pdf_image_paths, k=1)\n",
    "    \n",
    "    # --- Construct the Final Prompt ---\n",
    "    prompt = construct_prompt(new_design_text, new_design_image_url, retrieved_entries,\n",
    "                                pdf_relevant_texts)\n",
    "    \n",
    "    # Build conversation history (system + user)\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an expert design review engineer specializing in advanced shoe manufacturing. \"\n",
    "            \"Using the provided domain guidelines (extracted from a manufacturing PDF) and similar past design cases, \"\n",
    "            \"deliver a very specific evaluation focusing on manufacturability, material integration, curvature optimization, \"\n",
    "            \"sensor placement, and other critical factors.\"\n",
    "        )\n",
    "    }\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "    conversation_history = [system_message, user_message]\n",
    "    \n",
    "    # --- Call the OpenAI API ---\n",
    "    print(\"Calling OpenAI API for feedback...\")\n",
    "    feedback_response = chat_with_openai(conversation_history, api_key)\n",
    "    \n",
    "    # --- Print the Results ---\n",
    "    print(\"\\n----- OpenAI API Feedback -----\\n\")\n",
    "    print(feedback_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6907cdc2-2053-46f7-814d-1dbdb021de77",
   "metadata": {},
   "source": [
    "# proof-of-concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aad8a0-16f9-4133-9684-6db0f2694d58",
   "metadata": {},
   "source": [
    "new feedbacks from the domain expert (Alice): \n",
    "    concrete is not cofortable as a lining \n",
    "    sea sponge is not comfortable as a lining\n",
    "    cork cannot bond to rubber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6056885-6c18-4692-a881-d133cec63719",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./data/pdf/How_Shoes_Are_Made_Download_Edtion3.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc1995-aac2-486c-8823-0a990fb5c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path, max_chars=2000):\n",
    "    \"\"\"Extract text from a PDF file with a character limit.\"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    return text[:max_chars]  # Limit text to prevent exceeding token limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "196d1837-95d1-4560-9028-0642e10e7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "393491f5-74e3-4d1b-92bf-f516748f487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling OpenAI API for feedback...\n",
      "\n",
      "----- OpenAI API Feedback -----\n",
      "\n",
      "### Feasibility Analysis of Alpha Shoe 20 Design\n",
      "\n",
      "#### Design Overview:\n",
      "- **Lining**: SANG FANG sea sponge\n",
      "- **Heel**: Clarino synthetic 0.3mm\n",
      "- **Midsole**: Evertech EVA\n",
      "- **Outsole**: Evertech rubber\n",
      "- **Upper and Closure System**: Lightweight synthetic material with lace-up system\n",
      "- **Color Scheme**: Yellow Blaze and Light Grey\n",
      "- **Additional Features**: Triangular ventilation zones\n",
      "\n",
      "#### Feasibility Review by Components:\n",
      "\n",
      "1. **Lining (SANG FANG sea sponge)**:\n",
      "   - **Feasibility Concern**: The use of 'sea sponge' is unconventional and unspecified for practical application. The porosity and durability need clarification.\n",
      "   - **Feedback**: Verify the material's durability and comfort through prototype testing.\n",
      "   - **Improvement**: Consider using established lining materials like mesh textiles, which provide verified breathability and comfort.\n",
      "\n",
      "2. **Heel (Clarino synthetic 0.3mm)**:\n",
      "   - **Feasibility Concern**: The thickness (0.3mm) appears too thin for adequate structural reinforcement, especially in a performance-based basketball shoe.\n",
      "   - **Feedback**: Increase the thickness for better durability and support.\n",
      "   - **Improvement**: Assess a range around 0.8mm to 1.2mm based on prototyping results.\n",
      "\n",
      "3. **Midsole (Evertech EVA)**:\n",
      "   - **Feasibility**: High. EVA is standard in athletic shoes for cushioning.\n",
      "   - **Feedback**: Ensure the formulation of EVA is suited for high impact; create prototypes to test impact absorption.\n",
      "\n",
      "4. **Outsole (Evertech rubber)**:\n",
      "   - **Feasibility**: High. Rubber is appropriate, offering good traction.\n",
      "   - **Feedback**: The connection between the rubber outsole and the EVA midsole must be effectively bonded to prevent delamination.\n",
      "   - **Improvement**: Use high-quality adhesives and consider bonding techniques like vulcanization if appropriate.\n",
      "\n",
      "5. **Upper & Closure System**:\n",
      "   - **Feasibility Concern**: Lightweight synthetic materials must be evaluated for durability.\n",
      "   - **Feedback**: Test for flexibility, breathability, and endurance.\n",
      "   - **Improvement**: Integrate reinforcement zones in high-wear areas using techniques like heat-pressing or overlays.\n",
      "\n",
      "6. **Ventilation Zones and Color Scheme**:\n",
      "   - **Color Matching**: Ensure that the Yellow Blaze color on different materials (synthetic heel vs. rubber outsole) matches effectively across production lots.\n",
      "   - **Ventilation**: Validate the efficacy of the triangular ventilation zones in prototypes to ensure they provide enough air flow without compromising the shoe structure.\n",
      "\n",
      "#### Overall Feasibility Score: 75/100\n",
      "- **Main Concerns**: Material choices for the lining and heel thickness. Need for extensive prototyping to validate design choices particularly for breathability, comfort, and durability.\n",
      "- **Strengths**: Use of Evertech materials for midsole and outsole are industry-proven choices. The innovative design features could be appealing in the athletic market.\n",
      "\n",
      "#### Conclusion:\n",
      "The Alpha Shoe 20 presents a bold and innovative design with several high-performance features. However, the use of unconventional materials like SANG FANG sea sponge and the very thin Clarino synthetic raise practical concerns. Extensive testing is necessary, particularly in the areas of material durability and performance under athletic conditions. Improvements in material specifications and further prototype testing are recommended to enhance the overall feasibility and performance of the shoe.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pdfplumber\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# ================================\n",
    "# Initialize Models for Embeddings\n",
    "# ================================\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# ================================\n",
    "# File Paths\n",
    "# ================================\n",
    "new_design_image_path = \"./data/images/6.jpg\"\n",
    "\n",
    "# ================================\n",
    "# Helper Functions\n",
    "# ================================\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Convert an image to Base64 format after resizing.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((256, 256))  # Reduce image size to lower token usage\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    base64_image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return f\"data:image/jpeg;base64,{base64_image}\"\n",
    "\n",
    "def generate_text_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"Generate a text embedding using SentenceTransformer.\"\"\"\n",
    "    return text_model.encode(text)\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "def similarity_search(query_embedding: np.ndarray, database: list, k: int = 2):\n",
    "    \"\"\"Retrieve top-k similar cases from the synthetic database.\"\"\"\n",
    "    similarities = []\n",
    "    for entry in database:\n",
    "        entry_embedding = generate_text_embedding(entry[\"description\"])\n",
    "        sim = cosine_similarity(query_embedding, entry_embedding)\n",
    "        similarities.append((sim, entry))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# ================================\n",
    "# OpenAI Chat API Call Function\n",
    "# ================================\n",
    "def chat_with_openai(conversation_history, api_key):\n",
    "    \"\"\"Interact with OpenAI API using the latest interface.\"\"\"\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=conversation_history\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ================================\n",
    "# Construct the Final Prompt\n",
    "# ================================\n",
    "def construct_prompt(new_design_text: str, encoded_new_design_image: str,\n",
    "                     retrieved_entries: list, pdf_relevant_text: str) -> str:\n",
    "    \"\"\"Build a compact prompt with limited token usage.\"\"\"\n",
    "    prompt = f\"New Design Description:\\n{new_design_text}\\n\\n\"\n",
    "    prompt += \"New Design Image (Base64 Encoded):\\n\"\n",
    "    prompt += f\"{encoded_new_design_image}\\n\\n\"\n",
    "\n",
    "    prompt += \"Retrieved Similar Designs from Past Cases:\\n\"\n",
    "    for sim, entry in retrieved_entries:\n",
    "        prompt += f\"- description:{entry['description']} feedback:{entry['feedback']} (Similarity: {sim:.2f})\\n\"\n",
    "\n",
    "    prompt += \"Relevant Guidelines from PDF:\\n\"\n",
    "    prompt += f\"{pdf_relevant_text}\\n\\n\"\n",
    "\n",
    "    prompt += (\n",
    "        \"Analyze the manufacturability of this design based on best practices in footwear manufacturing. \"\n",
    "        \"Provide a feasibility score (0-100) along with specific feedback and improvements.\\n\\n\"\n",
    "        \"**Additional Verification Requirement:**\\n\"\n",
    "        \"Check each section/material element for feasibility and any errors/mismatches \"\n",
    "        \"with the location and color on the design.\"\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# ================================\n",
    "# Main Function\n",
    "# ================================\n",
    "def main():\n",
    "    api_key = \"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\"\n",
    "\n",
    "    # Encode the new design image (lower resolution)\n",
    "    encoded_new_design_image = encode_image_to_base64(new_design_image_path)\n",
    "\n",
    "    # New design description\n",
    "    new_design_text = \"\"\"\n",
    "Model: Alpha Shoe 20\n",
    "Style Code: SS26\n",
    "ID: 1000001\n",
    "\n",
    "The Alpha Shoe 20 is a high-performance basketball shoe designed for durability, comfort, and aesthetics. The design consists of the following material and color elements:\n",
    "\n",
    "Lining: Made from SANG FANG sea sponge in light grey, providing comfort and breathability.\n",
    "Heel: Constructed with Clarino synthetic 0.3mm material in Yellow Blaze, offering structural reinforcement and aesthetic contrast.\n",
    "Midsole: Composed of Evertech EVA in light grey, ensuring cushioning and impact absorption.\n",
    "Outsole: Engineered using Evertech rubber in Yellow Blaze, enhancing traction and grip on various surfaces.\n",
    "\n",
    "The shoe features a medial view with strategically placed triangular ventilation zones to enhance airflow. The lace-up closure system is designed for maximum foot lockdown and stability. The upper is constructed with a lightweight synthetic material to maintain a balance between flexibility and support.\n",
    "\n",
    "The color scheme primarily combines Yellow Blaze and Light Grey, providing a bold yet functional look suitable for high-performance athletes.\n",
    "\n",
    "Manufacturing Considerations:\n",
    "- Ensure proper bonding between Evertech rubber and EVA in the midsole and outsole.\n",
    "- Verify that Clarino synthetic 0.3mm is suitable for heel reinforcement without compromising flexibility.\n",
    "- Assess the comfort level of SANG FANG sea sponge as a lining material.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # --- Synthetic Database ---\n",
    "    synthetic_database = [\n",
    "        {\"id\": \"design_1\", \"description\": \"A modern sneaker with ergonomic features.\", \"feedback\": \"Sleek design but durability concerns.\"},\n",
    "        {\"id\": \"design_2\", \"description\": \"An athletic shoe with robust materials.\", \"feedback\": \"Solid design but complex upper construction.\"},\n",
    "        {\"id\": \"design_7\", \"description\": \"A shoe featuring a concrete lining.\", \"feedback\": \"Concrete is not viable as a lining. Must be a mistake.\"},\n",
    "        {\"id\": \"design_8\", \"description\": \"A sneaker with sea sponge lining.\", \"feedback\": \"Sea sponge is not possible as a lining.\"},\n",
    "        {\"id\": \"design_9\", \"description\": \"A cork sole bonded to a rubber base.\", \"feedback\": \"Cork cannot bond to rubber.\"}\n",
    "    ]\n",
    "\n",
    "    # --- RAG on Synthetic Database ---\n",
    "    query_embedding = generate_text_embedding(new_design_text)\n",
    "    retrieved_entries = similarity_search(query_embedding, synthetic_database, k=2)\n",
    "\n",
    "    # --- RAG on PDF Text ---\n",
    "    # print(\"Extracting text from PDF...\")\n",
    "    # pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    pdf_relevant_text = similarity_search_pdf_text(query_embedding, pdf_text, k=2)\n",
    "\n",
    "    # --- Construct the Final Prompt ---\n",
    "    prompt = construct_prompt(new_design_text, encoded_new_design_image, retrieved_entries, pdf_relevant_text)\n",
    "\n",
    "    # Build conversation history\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert shoe manufacturing, prototyping and development.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # --- Call OpenAI API ---\n",
    "    print(\"Calling OpenAI API for feedback...\")\n",
    "    feedback_response = chat_with_openai(conversation_history, api_key)\n",
    "\n",
    "    # --- Print the Results ---\n",
    "    print(\"\\n----- OpenAI API Feedback -----\\n\")\n",
    "    print(feedback_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eae0af-85f2-4a5a-936f-8f23b6fbe67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
